#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Sat Jul 20 11:57:37 2019

@author: valler
"""

from __future__ import division
import pandas as pd
from pandas import DataFrame
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.vector_ar.var_model import VAR
from statsmodels.tsa.stattools import adfuller as ADF
from statsmodels.tsa.stattools import kpss as KPSS
import math
#===============================================================
#basic information and graph
#===============================================================
def basicinfo(data,t1,t2):
    
    #print(data.info())
#graph 1&2
    data.ix[t1:t2].plot()
#info_hos.rolling(10).mean().plot()
    return;


#===============================================================
#Exponentially weighted windows and normal MA graph
#===============================================================
#graph 3
def ewm(data): # data is the train data
    fig, axes = plt.subplots(nrows=2, ncols=1, sharex=True, sharey=True,figsize=(12, 7))
    ma = data.rolling(20, min_periods=10).mean()
    ewma =data.ewm(span=20).mean()


    data.plot(style='k-', ax=axes[0])
    ma.plot(style='k--', ax=axes[0])
    data.plot(style='k-', ax=axes[1])
    ewma.plot(style='k--', ax=axes[1])
    axes[0].set_title('Simple MA')
    axes[1].set_title('Exponentially-weighted MA')
    return;
    
    

#===============================================================
#acf and pacf graph
#===============================================================
def acf(data):
#acf & pacf 
#graph 4&5
    from statsmodels.graphics.tsaplots import plot_acf
    plot_acf(data).show()
    from statsmodels.graphics.tsaplots import plot_pacf
    plot_pacf(data).show() #pacf

#===============================================================
#exam the stationarity 
#===============================================================
def unitroot(data,column): # column should be sth like u'DHOUST' 
    print('============================')
    print('This is result for ADF test')
    print('============================')
    print(ADF(data[column]))
    print('============================')
    print()
    print('============================')
    print('This is result for KPSS test')
    print('============================')
    print( KPSS(data[column]))
    print('============================')
    return;

#===============================================================
#take difference 
#===============================================================
def dif(data,column): # column is the new name,should be sth like u'DHOUST'
    Ddata= data.diff().dropna()
    Ddata.columns = [column]
    #graph6
    #Ddata.plot()  
    return Ddata;
    #print( ADF(Dhos_train[u'DHOUST']))
    #print( KPSS(Dhos_train[u'DHOUST']))

#===============================================================
#white noise test
#===============================================================
def whit(data,lagnum):
    from statsmodels.stats.diagnostic import acorr_ljungbox
    print(acorr_ljungbox(data, lags=lagnum))
    return;

#===============================================================
#ARMA model
#===============================================================
#decide p,q
def optilag(data,p,q): #p,q are the max length
    from statsmodels.tsa.arima_model import ARIMA
    pmax = p # for 
    qmax = q #suppose p,q < length/10
    bic_matrix = [] #bic matrix
    for p in range(pmax+1):
        tmp = []
        for q in range(qmax+1):
            try: 
                tmp.append(ARIMA(data, (p,0,q)).fit().bic)
            except:
                tmp.append(None)
            bic_matrix.append(tmp)
            '''
            lag check
            print('============================')
            print('============================')
            
            print('this is tmp:')
            print(tmp)
            print(u'p值和q值为：%s、%s' %(p,q))
            print('============================')
            print('============================')
            '''
    bic_matrix = pd.DataFrame(bic_matrix) #find the minimum 
    #print('============================')
    #print('============================')
    #print(bic_matrix)
    p,q = bic_matrix.stack().idxmin()
    #print('============================')
    #print('============================')
    print()
    print('============================')
    print('============================')
    p= math.ceil(p/4)
    print(u'BIC最小的p值和q值为：%s、%s' %(p,q)) 
    print('============================')
    print('============================') 
    M=[]
    M.append(p)
    M.append(q)
    return M;
#-------------------------------------------------    
def model(data,p,d,q,fre):#ARIMA(p,d,q) 
    from statsmodels.tsa.arima_model import ARIMA
    model = ARIMA(data,(p,d,q),freq=fre,start_ar_lags=p).fit(disp=False) 
    #print('============================')
    #print('modelsummary!!') #model report
    #print('============================')
    #print(model.summary())
    print('============================')
    print('Forecast Result') #model report
    print('============================')
    Fore=model.forecast(1)
    print(Fore)
    return Fore;
#-------------------------------------------------
def arpredict(data,p,d,q,t1,t2):
    from statsmodels.tsa.arima_model import ARIMA
    model=ARIMA(data,(p,d,q))
    pre =model.predict(data)
    return pre;


#===============================================================
#VAR
#===============================================================

def var(data,columnx,columny,columnz,columnn,fre): #data here should be a complete data
    info_var = data[[columnx,columny,columnz,columnn]]
    #optlag = VAR(info_var).select_order(trend='c')
    #print(optlag)
    model = VAR(info_var).fit(maxlags=10,method='ols', ic='aic', trend='c',freq=fre)
    yhat =model.forecast(model.y,1)
    print(yhat)

    return yhat;

#===============================================================
#HWES
#===============================================================

def hwes(hos_train,fre):
    from statsmodels.tsa.holtwinters import ExponentialSmoothing
    model = ExponentialSmoothing(hos_train,freq=fre).fit()    
    #forec = model.predict(len(hos_train), len(hos_train))
    forec = model.forecast(1)
    print('============================')
    print('============================')
    print('This is the forecast result')
    print(forec)
    print('============================')
    print('============================')
    print()
    return forec;


#===============================================================
#VARMA
#===============================================================
def varmax(data,columnx,columny,columnz,columnn,fre):
    from statsmodels.tsa.statespace.varmax import VARMAX
# fit model   
    info_varmax = data[[columnx,columny,columnz,columnn]]
    

    bic_matrix = [] #bic matrix
    for p in range(3):
        tmp = []
        for q in range(3):
            try:
                m=VARMAX(info_varmax,order=(p,q),freq=fre).fit(disp=False).bic
                print(u'for order：%s、%s' %(p,q))
                print(u'the bic is:%s'%(m))
                tmp.append(m)
            except:
                tmp.append(None)
        bic_matrix.append(tmp)
            
    #lag check
    '''
    print('============================')
    print('============================')
    
    print('this is bic_matrix:')
    print(bic_matrix)
    print()
    print(u'p值和q值为：%s、%s' %(p,q))
    print('============================')
    print('============================')
            
    bic_matrix = pd.DataFrame(bic_matrix) #find the minimum 
    #print('============================')
    #print('============================')
    #print(bic_matrix)
    p,q = bic_matrix.stack().idxmin()
    print(u'MINIMUM p值和q值为：%s、%s' %(p,q))
    '''
    #model = VARMAX(info_var,order=(2, 2))
    #model_fit = model.fit(disp=False)
    #res =model.VARMAXResults()  
    #bic=model_fit.bic
    
# make prediction
    #data_exog2 = [[100]]
    model = VARMAX(info_var,order=(p,q),freq=fre)
    model_fit = model.fit(disp=False)
    yhat =model_fit.forecast(1)
    print('============================')
    print('============================')
    print('This is the forecast result')
    print(yhat)
    print('============================')
    print('============================')
    
    return yhat;   


#===============================================================
#Model evaluating
#===============================================================
def rmse(actual,predict):#data1 is actual data
    from sklearn.metrics import mean_squared_error
    from math import sqrt


    rms = sqrt(mean_squared_error(actual,predict))
    return rms;  

 
def modeleva(model,actual,predict):
    import  statsmodels.tools.eval_measures as ev
    
    if model =='mse':
        res=ev.mse(actual,predict).mean()
    elif model == 'rmse':
        res =ev.rmse(actual,predict).mean()
    elif model == 'MAPE':
        x1 = np.asanyarray(actual)
        x2 = np.asanyarray(predict)
        res = np.mean(np.abs((x1 - x2) / x1)).mean()
    else:
        res = 'no such mean'
    
    return res;



#===============================================================
#     |
    #main 
#     |
#===============================================================
    #basicinfo(data,t1,t2)
    #ewm(data): # data is the train data
    #acf(data)
    #unitroot(data,column)
    #dif(data,column)
    #whit(data,lagnum)
    #optilag(data,p,q) #p,q are the max length
    #model(data,p,d,q) #ARIMA(p,d,q) 
    #arpredict(data,p,d,q,t1,t2)
    #var(data,columny,columnx): #data here should be a complete data
    #varmax(info_all,'HOUST','HOUSTS'),data here should be a complete data
    #hwes(data)
#===============================================================
    
    
    
    
#===============================================================
#read data
#---------------------------------------------------------------   
filename='2019-07.csv' #'2019-06.csv' 
fre='QS'
#----------------

info_all = pd.read_csv(filename, parse_dates=True, index_col=0)
d=pd.read_csv(filename) # get time sequence
df=d['sasdate']#data index 
df= pd.to_datetime(df)

#----------------
columnx='USSTHPI'#House price,All-Transactions House Price Index for the United States (Index 1980 Q1=100),
#starts from 1975-3-1,df[64]
columny='GDPC1'#GDP,Real Gross Domestic Product, 3 Decimal (Billions of Chained 2012 Dollars)
columnz='CPIAUCSL'#CPI,Consumer Price Index for All Urban Consumers: All Items (Index 1982-84=100)
columnn='PPIACO' #PPI,Producer Price Index for All Commodities (Index 1982=100)
#----------------
info_hos=info_all[columnx]
#hos_train = info_hos['1959-01-01':'2001-01-01']
#----------------

#===============================================================
#check for stationarity
#---------------------------------------------------------------

basicinfo(info_all[columnx],df[0],df[241])
basicinfo(info_all[columny],df[0],df[241])
basicinfo(info_all[columnz],df[0],df[241])
basicinfo(info_all[columnn],df[0],df[241])

#===============================================================
#loop for VARMAX,VAR,HWES,ARIMA
#---------------------------------------------------------------
#for MD 
#1959-01-01 is df[0]
# 2001-01-01 is df[504]
# 2001-02-01 is df[505]
# 2019-05-01 is df[724]
#max df: 725, 2019-06-01

#for QD
#242 entries, 1959-03-01 to 2019-06-01
#1959-03-01 00:00:00 df[0]
#2001-06-01 00:00:00 df[169]
#2001-09-01 00:00:00 df[170]
#2019-06-01 00:00:00 df[241]
#===============================================================
#'''

j=0
i=504
q=506 # the end point of forecasting
p=i+1 # start point of forecasting
# forecast range: [p,q],length:q-p+1

m=1# 1: VARMA 2: VAR 3:HWES ELSE: ARIMA
foresult=DataFrame() # for VARMAX
tmp = []
var1 = []
var2= []
while i<q: #change point 1  
    train = info_all[df[j]:df[i]]
    
    if m==1: #VARMAX
        fore= varmax(train,columnx,columny)
        print(fore) 
        foresult=foresult.append(fore)
        
    elif m==2:#VAR
        fore= var(train,columnx,columny)
        a= fore[0] 
        var1.append(a[0])
        var2.append(a[1])
        
    elif m==3:  #HWES,tmp
        trainh=train[columnx]
        fore= hwes(trainh)
        print(fore[0]) 
        tmp.append(fore[0])

    else: #ARMA,tmp
        trainh=train[columnx]
        M=optilag(trainh,4,3)
        fore= model(trainh,M[0],0,M[1])
        print(fore)
        a= fore[0]  
        tmp.append(a[0]) 
 

    i = i+1
    j=j+1
    
    print('This is J: %s' %(j))
    continue;

#print result
print(foresult)
print(tmp)
print(var1)
print(var2)


#plot 
#'''
info_var = info_all[[columnx,columny]]
info_hos = info_all[columnx]
info_hos1 = info_all[columny]


if m==1:#VARMAX
    ax = info_var.ix[df[p]:df[q]].plot(style='k-')# change point 3,originial data
    foresult.plot(color='blue',ax=ax,title='forecast')
    
    #-----calculate MSE,RMSE...------
    '''
    print('============================')
    print('============================')
    rmse1=modeleva('MAPE',info_hos[df[p]:df[q]],foresult[columnx])
    rmse2=rmse(info_hos[df[p]:df[q]],foresult[columny])
    print(u'The RMSE for %s is: %s'%(columnx,rmse1))
    print('============================')
    print('============================')
    print(u'The RMSE of %s is: %s'%(columny,rmse2))
    
    #-----write to csv------
    comb=pd.concat([foresult,info_var[df[p]:df[q]]],axis=1)
    comb.to_csv('VARMAX_Foresult.csv')
    #'''
elif m==2:#VAR
    ax = info_var.ix[df[p]:df[q]].plot(style='k-')
    foresult1=DataFrame(var1,index=pd.date_range('2/1/2001', periods=q-p+1, freq=fre))# 
    foresult1.columns =[columnx +' Fore']

    foresult2=DataFrame(var2,index=pd.date_range('2/1/2001',periods=q-p+1, freq=fre))#
    foresult2.columns =[columny+' Housts Fore']
    
    comb =pd.concat([foresult1,foresult2],axis=1)
    comb.plot(color='blue',ax=ax,title='ARMA forecast')
    
    #-----calculate MSE,RMSE...------
    print('============================')
    print('============================')
    rmse1=rmse(info_hos[df[p]:df[q]],foresult1)
    print(u'The RMSE of HOUST is: %s'%(rmse1))
    print('============================')
    print('============================') 
    rmse2=rmse(info_hos1[df[p]:df[q]],foresult2)#change point
    print(u'The RMSE of HOUSTS is: %s'%(rmse2))
    
    #-----write to csv------
    #comb1=pd.concat([comb,info_hos[df[p]:df[q]]],axis=1)
    #comb1.to__csv('VAR_Foresult.csv')
    
elif m==3:#HWES
    ax = info_hos.ix[df[p]:df[q]].plot(style='k-')# change point 3,originial data
    foresult=DataFrame(tmp,index=pd.date_range('2/1/2001', periods=q-p+1, freq=fre))# change point 2
    foresult.columns =['Houst Fore']
    foresult.plot(color='blue',ax=ax,title='HWES Forecast')
   
    
    #-----calculate MSE,RMSE...------
    print('============================')
    print('============================')
    rmse=modeleva('MAPE',info_hos[df[p]:df[q]],foresult)
    print(u'The Evaluation value is: %s'%(rmse)) 
    
    
    #-----write to csv------
    #comb =pd.concat([foresult,info_hos[df[p]:df[q]]],axis=1)
    #comb.to_csv('HWES_Foresult.csv')
else:#ARMA
    ax = info_hos.ix[df[p]:df[q]].plot(style='k-')
    foresult=DataFrame(tmp,index=pd.date_range('2/1/2001', periods=q-p+1, freq=fre))# change point 2
    foresult.columns =['Houst Fore']
    foresult.plot(color='blue',ax=ax,title='ARMA forecast')
    
    #-----calculate MSE,RMSE...------
    print('============================')
    print('============================')
    rmse=modeleva('MAPE',info_hos[df[p]:df[q]],foresult)
    print(u'The Evaluation value is: %s'%(rmse))    
    
    #-----write to csv------
    #foresult.to_csv('ARMA_Foresult.csv')

#'''








