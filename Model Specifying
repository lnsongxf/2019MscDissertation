#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Sat Jul 20 11:57:37 2019

@author: valler
"""

from __future__ import division
import pandas as pd
from pandas import DataFrame
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.vector_ar.var_model import VAR
from statsmodels.tsa.stattools import adfuller as ADF
from statsmodels.tsa.stattools import kpss as KPSS
import math
#===============================================================
#basic information and graph
#===============================================================
def basicinfo(data,t1,t2):
    
    #print(data.info())
#graph 1&2
    data.ix[t1:t2].plot()
#info_hos.rolling(10).mean().plot()
    return;


#===============================================================
#Exponentially weighted windows and normal MA graph
#===============================================================
#graph 3
def ewm(data): # data is the train data
    fig, axes = plt.subplots(nrows=2, ncols=1, sharex=True, sharey=True,figsize=(12, 7))
    ma = data.rolling(20, min_periods=10).mean()
    ewma =data.ewm(span=20).mean()


    data.plot(style='k-', ax=axes[0])
    ma.plot(style='k--', ax=axes[0])
    data.plot(style='k-', ax=axes[1])
    ewma.plot(style='k--', ax=axes[1])
    axes[0].set_title('Simple MA')
    axes[1].set_title('Exponentially-weighted MA')
    return;
    
    

#===============================================================
#acf and pacf graph
#===============================================================
def acf(data):
#acf & pacf 
#graph 4&5
    from statsmodels.graphics.tsaplots import plot_acf
    plot_acf(data).show()
    from statsmodels.graphics.tsaplots import plot_pacf
    plot_pacf(data).show() #pacf

#===============================================================
#exam the stationarity 
#===============================================================
def unitroot(data,column): # column should be sth like u'DHOUST' 
    print('============================')
    print('This is result for ADF test')
    print('============================')
    print(ADF(data[column]))
    print('============================')
    print()
    print('============================')
    print('This is result for KPSS test')
    print('============================')
    print( KPSS(data[column]))
    print('============================')
    return;

#===============================================================
#take difference 
#===============================================================
def dif(data,column): # column is the new name,should be sth like u'DHOUST'
    Ddata= data.diff().dropna()
    Ddata.columns = [column]
    #graph6
    Ddata.plot()  
    return Ddata;
    #print( ADF(Dhos_train[u'DHOUST']))
    #print( KPSS(Dhos_train[u'DHOUST']))

#===============================================================
#white noise test
#===============================================================
def whit(data,lagnum):
    from statsmodels.stats.diagnostic import acorr_ljungbox
    print(acorr_ljungbox(data, lags=lagnum))
    return;

#===============================================================
#ARMA model
#===============================================================
#decide p,q
def optilag(data,p,q,fre): #p,q are the max length
    from statsmodels.tsa.arima_model import ARIMA
    pmax = p # for 
    qmax = q #suppose p,q < length/10
    x=0
    bic_matrix = [] #bic matrix
    for p in range(pmax):
        tmp = []
        for q in range(qmax):
            try:
                x =ARIMA(data, (p,0,q),freq=fre).fit().bic
                if math.isnan(x):
                    tmp.append(None)
                else:
                    tmp.append(x)
            except:
                tmp.append(None)
            bic_matrix.append(tmp)
            '''
            lag check
            print('============================')
            print('============================')
            
            print('this is tmp:')
            print(tmp)
            print(u'p值和q值为：%s、%s' %(p,q))
            print('============================')
            print('============================')
            '''
    bic_matrix = pd.DataFrame(bic_matrix) #find the minimum 
    #print('============================')
    #print('============================')

    bic_matrix.fillna(5000,inplace=True)
    print(bic_matrix)
    p,q = bic_matrix.stack().idxmin()
    #print('============================')
    #print('============================')
    print()
    print('============================')
    print('============================')
    p= math.ceil(p/4)
    print(u'BIC最小的p值和q值为：%s、%s' %(p,q)) 
    print('============================')
    print('============================') 
    M=[]
    M.append(p)
    M.append(q)
    return M;
#-------------------------------------------------    
def model(data,p,d,q,fre):#ARIMA(p,d,q) 
    from statsmodels.tsa.arima_model import ARIMA
    model = ARIMA(data,(p,d,q),freq=fre).fit(disp=False) 
    #print('============================')
    #print('modelsummary!!') #model report
    #print('============================')
    #print(model.summary())
    print('============================')
    print('Forecast Result') #model report
    print('============================')
    Fore=model.forecast(1)
    print(Fore)
    return Fore;

#===============================================================
#VAR
#===============================================================

def var(data,columnx,columny,columnz,columnn,fre): #data here should be a complete data
    info_var = data[[columnx,columny,columnz,columnn]]
    #optlag = VAR(info_var).select_order(trend='c')
    #print(optlag)
    model = VAR(info_var,freq=fre).fit(maxlags=10,method='ols', ic='aic', trend='c')
    yhat =model.forecast(model.y,1)
    print(yhat)

    return yhat;

#===============================================================
#HWES
#===============================================================

def hwes(hos_train,fre,level):
    from statsmodels.tsa.holtwinters import ExponentialSmoothing
    model = ExponentialSmoothing(hos_train,freq=fre).fit(smoothing_level=level)    
    #forec = model.predict(len(hos_train), len(hos_train))
    forec = model.forecast(1)
    print('============================')
    print('============================')
    print('This is the forecast result')
    print(forec)
    print('============================')
    print('============================')
    print()
    return forec;


#===============================================================
#VARMA
#===============================================================
def varmax(data,columnx,columny,columnz,columnn,fre):
    from statsmodels.tsa.statespace.varmax import VARMAX
# fit model   
    info_varmax = data[[columnx,columny,columnz,columnn]]
    

    bic_matrix = [] #bic matrix
    for p in range(3):
        tmp = []
        for q in range(3):
            try:
                m=VARMAX(info_varmax,order=(p,q),freq=fre).fit(disp=False).bic
                print(u'for order：%s、%s' %(p,q))
                print(u'the bic is:%s'%(m))
                tmp.append(m)
            except:
                tmp.append(None)
        bic_matrix.append(tmp)
   
    #lag check

    print('============================')
    print('============================')
    
    print('this is bic_matrix:')
    print(bic_matrix)
    print()
    print(u'p值和q值为：%s、%s' %(p,q))
    print('============================')
    print('============================')
            
    bic_matrix = pd.DataFrame(bic_matrix) #find the minimum 
    bic_matrix.fillna(5000,inplace=True) 
    #print('============================')
    #print('============================')
    #print(bic_matrix)
    p,q = bic_matrix.stack().idxmin()
    print(u'MINIMUM p值和q值为：%s、%s' %(p,q))

    #model = VARMAX(info_var,order=(2, 2))
    #model_fit = model.fit(disp=False)
    #res =model.VARMAXResults()  
    #bic=model_fit.bic
    
# make prediction
    #data_exog2 = [[100]]
    if p==0:
        if q==0:
            p=1
            q=1
            
    model = VARMAX(info_varmax,order=(p,q),freq=fre)
    model_fit = model.fit(disp=False)
    yhat =model_fit.forecast(1)
    print('============================')
    print('============================')
    print('This is the forecast result')
    print(yhat)
    print('============================')
    print('============================')
    
    return yhat;   


#===============================================================
#Model evaluating
#===============================================================
def rmse(actual,predict):#data1 is actual data
    from sklearn.metrics import mean_squared_error
    from math import sqrt


    rms = sqrt(mean_squared_error(actual,predict))
    return rms;  

 
def modeleva(model,actual,predict):
    import  statsmodels.tools.eval_measures as ev
    
    if model =='mse':
        res=ev.mse(actual,predict).mean()
    elif model == 'rmse':
        res =ev.rmse(actual,predict).mean()
    elif model == 'MAPE':
        x1 = np.asanyarray(actual)
        x2 = np.asanyarray(predict)
        res = np.mean(np.abs((x1 - x2) / x1)).mean()
    else:
        res = 'no such mean'
    
    return res;



#===============================================================
#     |
    #main 
#     |
#===============================================================
    #basicinfo(data,t1,t2)
    #ewm(data): # data is the train data
    #acf(data)
    #unitroot(data,column)
    #dif(data,column)
    #whit(data,lagnum)
    #optilag(data,p,q) #p,q are the max length
    #model(data,p,d,q) #ARIMA(p,d,q) 
    #arpredict(data,p,d,q,t1,t2)
    #var(data,columny,columnx): #data here should be a complete data
    #varmax(info_all,'HOUST','HOUSTS'),data here should be a complete data
    #hwes(data)
#===============================================================
    
    
    
    
#===============================================================
#read data
#---------------------------------------------------------------   
filename='2019-07.csv' #'2019-06.csv' 
fre='QS-DEC'
forest='9/1/2001'
#----------------

info_all = pd.read_csv(filename, parse_dates=True, index_col=0)
d=pd.read_csv(filename) # get time sequence
df=d['sasdate']#data index 
df= pd.to_datetime(df)

#----------------
columnx='PCECC96'#Real Personal Consumption Expenditures (Billions of Chained 2012 Dollars)
#'USSTHPI' House price,All-Transactions House Price Index for the United States (Index 1980 Q1=100),
#starts from 1975-3-1,df[64]
columny='GDPC1'#GDP,Real Gross Domestic Product, 3 Decimal (Billions of Chained 2012 Dollars)
columnz='CPIAUCSL'#CPI,Consumer Price Index for All Urban Consumers: All Items (Index 1982-84=100)
columnn='PPIACO' #PPI,Producer Price Index for All Commodities (Index 1982=100)
#----------------
info_hos=info_all[columnx]
#hos_train = info_hos['1959-01-01':'2001-01-01']
#----------------

#===============================================================
#check for stationarity
#---------------------------------------------------------------
'''
#graph
basicinfo(info_all[columnx],df[0],df[241])
basicinfo(info_all[columny],df[0],df[241])
basicinfo(info_all[columnz],df[0],df[241])
basicinfo(info_all[columnn],df[0],df[241])

#diff
Ddatax=info_all[columnx].diff().dropna()
Ddatax=Ddatax.to_frame()
Ddatax.columns =[columnx]
Ddatax.plot()

Ddatay=info_all[columny].diff().dropna()
Ddatay=Ddatay.to_frame()
Ddatay.columns =[columny]
Ddatay.plot()

Ddataz=info_all[columnz].diff().dropna()
Ddataz=Ddataz.to_frame()
Ddataz.columns =[columnz]
Ddataz.plot()

Ddatan=info_all[columnn].diff().dropna()
Ddatan=Ddatan.to_frame()
Ddatan.columns =[columnn]
Ddatan.plot()

comb=pd.concat([Ddatax,Ddatay,Ddataz,Ddatan],axis=1)
comb.to_csv('Diff_result.csv')
'''
#re-read data

info_all = pd.read_csv('Diff_result.csv', parse_dates=True, index_col=0)
d=pd.read_csv('Diff_result.csv') # get time sequence
df=d['sasdate']#data index 
df= pd.to_datetime(df)


'''
unitroot(info_all,columnx) #stationary now,diff 3 times
unitroot(info_all,columny) #stationary now,diff 3 times
unitroot(info_all,columnz) #stationary now,diff 3 times
unitroot(info_all,columnn) #stationary now,diff twice
'''
#===============================================================
#loop for VARMAX,VAR,HWES,ARIMA
#---------------------------------------------------------------
#for MD 
#1959-01-01 is df[0]
# 2001-01-01 is df[504]
# 2001-02-01 is df[505]
# 2019-05-01 is df[724]
#max df: 725, 2019-06-01

#for QD
#239 entries, 1959-12-01 to 2019-06-01
#1959-12-01 00:00:00 df[0]
#2001-06-01 00:00:00 df[166]
#2001-09-01 00:00:00 df[167]
#2019-06-01 00:00:00 df[238]
#===============================================================
#'''

j=0
i=166
q=238 # the end point of forecasting
p=i+1 # start point of forecasting
# forecast range: [p,q],length:q-p+1

m=3# 1: VARMA 2: VAR 3:HWES ELSE: ARIMA
foresult=DataFrame() # for VARMAX
tmp = []
var1 = []
var2= []
var3= []
var4=[]
level=0.7

while i<q: #change point 1  
    train = info_all[df[j]:df[i]]
    if m==1: #VARMAX
        fore= varmax(train,columnx,columny,columnz,columnn,fre)
        print(fore) 
        foresult=foresult.append(fore)
        
    elif m==2:#VAR
        fore= var(train,columnx,columny,columnz,columnn,fre)
        a= fore[0] 
        var1.append(a[0])
        var2.append(a[1])
        var3.append(a[2])
        var4.append(a[3])
        
    elif m==3:  #HWES,tmp
        trainh=train[columnn]
        fore= hwes(trainh,fre,level)
        print(fore[0]) 
        tmp.append(fore[0])

    else: #ARMA,tmp
        trainh=train[columnx]
        M=optilag(trainh,4,3,fre)
        fore= model(trainh,M[0],0,M[1],fre)
        print(fore)
        a= fore[0]  
        tmp.append(a[0]) 
 

    i = i+1
    j=j+1
    
    print('This is J: %s' %(j))
    continue;

#print result
print(foresult)
print(tmp)
print(var1)
print(var2)
print(var3)
print(var4)

#plot 
#'''
info_var = info_all[[columnx,columny,columnz,columnn]]

info1=info_all[columnx]
info1=info1.to_frame()
info1.columns=[columnx]

info2=info_all[columny] 
info2=info2.to_frame()
info2.columns=[columny]
 
info3=info_all[columnz]
info3=info3.to_frame()
info3.columns=[columnz]

info4=info_all[columnn]
info4=info4.to_frame()
info4.columns=[columnn]

if m==1:#VARMAX

    #foresult.columns=[columnx+' Fore',columny+' Fore',columnz+' Fore',columnn+' Fore']
    ax1 = info4.ix[df[p]:df[q]].plot()#
    pl=foresult[columnn+' Fore']
    pl=pl.to_frame()
    pl.columns=[columnn+' Fore']
    pl.plot(color='orange',ax=ax1,title='VARMAX forecast')

    #-----calculate MSE,RMSE...------
    '''
    print('============================')
    print('============================')
    rmse1=modeleva('MAPE',info1[df[p]:df[q]],foresult[columnx])
    rmse2=rmse(info2[df[p]:df[q]],foresult[columny])
    print(u'The RMSE for %s is: %s'%(columnx,rmse1))
    print('============================')
    print('============================')
    print(u'The RMSE of %s is: %s'%(columny,rmse2))
    
    #-----write to csv------
    comb=pd.concat([foresult,info_var[df[p]:df[q]]],axis=1)
    comb.to_csv('VARMAX_Foresult_QD.csv')
    #'''
elif m==2:#VAR
    ax1 = info1.ix[df[p]:df[q]].plot()
    foresult1=DataFrame(var1,index=pd.date_range(forest, periods=q-p+1, freq=fre))# 
    foresult1.columns =[columnx +' Fore']
    foresult1.plot(color='orange',ax=ax1,title='VAR forecast')
    
    ax2 = info2.ix[df[p]:df[q]].plot()
    foresult2=DataFrame(var2,index=pd.date_range(forest,periods=q-p+1, freq=fre))#
    foresult2.columns =[columny+' Fore']
    foresult2.plot(color='orange',ax=ax2,title='VAR forecast')
    
    ax3 = info3.ix[df[p]:df[q]].plot()    
    foresult3=DataFrame(var3,index=pd.date_range(forest,periods=q-p+1, freq=fre))#
    foresult3.columns =[columnz+' Fore']
    foresult3.plot(color='orange',ax=ax3,title='VAR forecast')
 
    ax4 = info4.ix[df[p]:df[q]].plot()
    foresult4=DataFrame(var4,index=pd.date_range(forest,periods=q-p+1, freq=fre))#
    foresult4.columns =[columnn+' Fore']
    foresult4.plot(color='orange',ax=ax4,title='VAR forecast')
    
    comb =pd.concat([foresult1,foresult2,foresult3,foresult4],axis=1)

    #-----calculate MSE,RMSE...------
    '''
    print('============================')
    print('============================')
    rmse1=rmse(info1[df[p]:df[q]],foresult1)
    print(u'The RMSE of HOUST is: %s'%(rmse1))
    print('============================')
    print('============================') 
    rmse2=rmse(info2[df[p]:df[q]],foresult2)#change point
    print(u'The RMSE of HOUSTS is: %s'%(rmse2))
    '''
    #-----write to csv------
    #comb1=pd.concat([comb,info_var[df[p]:df[q]]],axis=1)
    #comb1.to_csv('VAR_Foresult_QD.csv')
    
elif m==3:#HWES
    ax = info4.ix[df[p]:df[q]].plot()# change point 3,originial data
    foresult=DataFrame(tmp,index=pd.date_range(forest, periods=q-p+1, freq=fre))# change point 2
    foresult.columns =[columnn+' Fore a=0.7']
    foresult.plot(color='orange',ax=ax,title='HWES Forecast')
    fore47=foresult
    #-----calculate MSE,RMSE...------
    '''
    print('============================')
    print('============================')
    rmse=modeleva('MAPE',info1[df[p]:df[q-1]],foresult)
    print(u'The Evaluation value is: %s'%(rmse)) 
    '''
    #fore2=foresult
    #-----write to csv------
    #comb =pd.concat([fore15,fore16,fore17,fore25,fore26,fore27,fore35,fore36,fore37,fore45,fore46,fore47,info_var[df[p]:df[q]]],axis=1)
    #comb.to_csv('HWES_Foresult_QD.csv')
else:#ARMA
    ax = info1.ix[df[p]:df[q-1]].plot()
    foresult=DataFrame(tmp,index=pd.date_range(forest, periods=q-p+1, freq=fre))# change point 2
    foresult.columns =[columnx+' Fore']
    foresult.plot(color='orange',ax=ax,title='ARMA Forecast')
    
    #-----calculate MSE,RMSE...------
    '''
    print('============================')
    print('============================')
    rmse1=modeleva('mse',info1[df[p]:df[q-1]],foresult)
    print(u'The Evaluation value is: %s'%(rmse1))    
    '''
    #-----write to csv------

   
    
    #comb =pd.concat([info_var[df[p]:df[q-1]],fore1,fore2,fore3,fore4],axis=1)
    #comb.to_csv('ARMA_Foresult_QD.csv')
    
#'''

#===============================================================
#Model Average
#===============================================================


#===============================================================
#===============================================================






